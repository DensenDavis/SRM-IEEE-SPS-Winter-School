{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhqXxpamFARq"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi # Check whether your system has a GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_url = \"https://drive.google.com/file/d/1Ru1dLP8vXUnVbDiwQqf--qyiYkHd9C_1/view?usp=share_link\"\n",
        "!gdown 1Ru1dLP8vXUnVbDiwQqf--qyiYkHd9C_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "shutil.unpack_archive('flower_photos.tgz','./')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!rm -rf  flower_photos/LICENSE.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "names = os.listdir('flower_photos')\n",
        "os.makedirs(os.path.join('flower_photos/train/'),exist_ok=True)\n",
        "for name in names:\n",
        "    shutil.move(f'flower_photos/{name}',f'flower_photos/train/')\n",
        "    os.makedirs(os.path.join('flower_photos/validation/',name),exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "train_names = os.listdir('flower_photos/train/')\n",
        "for train_name in train_names:\n",
        "    file_names = sorted(os.listdir(os.path.join('flower_photos/train/',train_name)))\n",
        "    for file_name in file_names[-100:]:\n",
        "        shutil.move(os.path.join('flower_photos/train/',train_name,file_name),os.path.join('flower_photos/validation/',train_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTN7o73CxpU0"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NoduTJIqEvv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import torch \n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_ycU-vBtaCv"
      },
      "source": [
        "numpy \n",
        "- A scientific computing library\n",
        "- Supports array operations and manipulations\n",
        "- Built-in functions like array sum, diff, mean, average, min, max etc.\n",
        "\n",
        "cv2\n",
        "- To read and write images\n",
        "- To perform basic vision algorithms like RGB to HSV, Gaussian Blur, Dilation, Histogram, Shape detection etc.\n",
        "\n",
        "torch\n",
        "- The open source ML framework for deep learning\n",
        "- Has a pythonic interface\n",
        "\n",
        "torchvision\n",
        "- consists of popular datasets, model architectures, and common image transformations for computer vision\n",
        "- Contains built in data augmentations\n",
        "\n",
        "matplotlib\n",
        "- It is a data visualization library for python\n",
        "- It supports graphical plotting and viewing images and other data\n",
        "\n",
        "nn\n",
        "- The base module with which we can create and train neural nets\n",
        "- Provides built-in classes for common neural network layers like Conv, Pooling, Activations, Normalizations, Dropout etc.\n",
        "\n",
        "optim\n",
        "- It is a package for implementing various optimization algorithms for model training\n",
        "- Built-in optimizers like SGD, Adam, Adagrad, RMSprop etc.\n",
        "\n",
        "tqdm\n",
        "- It is a library used to display a progress bar for loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8Qbwuzdx0dH"
      },
      "source": [
        "# Preprocess inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVcCk-6TyvEy"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor()]) # Define the set of transformations to be applied on the input data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lFD-xj8qWVc"
      },
      "outputs": [],
      "source": [
        "# transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,)),])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xeJCeo3yE9Z"
      },
      "source": [
        "ToTensor()\n",
        " - converts the image with a pixel range of [0, 255] to a PyTorch FloatTensor of shape (C, H, W) with a range [0.0, 1.0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uzgtjA4xCnv"
      },
      "source": [
        "Normalize() \n",
        "- output[channel] = (input[channel] - mean[channel]) / std[channel]\n",
        "\n",
        "- Normalization helps get data within a range and reduces the skewness which helps learn faster and better. \n",
        "- Normalization can also tackle the diminishing and exploding gradients problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dZes3DQzlsm"
      },
      "source": [
        "# Custom Dataloaders using Image Folder function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_oL6gEw01fO"
      },
      "source": [
        "- Combines a dataset and a sampler\n",
        "- Provides an iterable over the given dataset\n",
        "- Supports single- or multi-process loading\n",
        "- Customizing loading order\n",
        "- Automatic batching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainset = datasets.ImageFolder(root ='flower_photos/train',transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-258nSWz5i9"
      },
      "outputs": [],
      "source": [
        "valset = datasets.ImageFolder(root ='flower_photos/validation',transform=transform)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=8, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDZYc7_xz-tM"
      },
      "outputs": [],
      "source": [
        "dataiter = iter(trainloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Cxx5qFSCMdl"
      },
      "source": [
        "Now that we have an iterator, let's visualize our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9Qg2ipB0Acv"
      },
      "outputs": [],
      "source": [
        "images, gt_labels = dataiter.next() # The first minibatch of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVoe0YEL0Dtu"
      },
      "outputs": [],
      "source": [
        "print(images.shape)\n",
        "print(gt_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTOnzN15uaN8"
      },
      "outputs": [],
      "source": [
        " # Visualize an image sample\n",
        "plt.imshow((images[2].squeeze()).permute(1,2,0).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classes = trainset.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBvtMO96ud6w"
      },
      "outputs": [],
      "source": [
        "# Visualize all images in the minibatch\n",
        "figure = plt.figure()\n",
        "total_samples = 8\n",
        "for index in range(1,total_samples+1):\n",
        "    ax = plt.subplot(2, 4, index)\n",
        "    ax.set_xlabel(classes[gt_labels[index-1].item()])\n",
        "    # plt.axis('off')\n",
        "    plt.imshow(images[index-1].squeeze().permute(1,2,0).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9u1I-5qDGiQV"
      },
      "outputs": [],
      "source": [
        "# Visualize the Ground truth labels\n",
        "print(gt_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qr_TSdxjGo5k"
      },
      "outputs": [],
      "source": [
        "# Visualize the onehot encoding of the labels\n",
        "onehot_labels = nn.functional.one_hot(gt_labels, num_classes=10)\n",
        "print(onehot_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Let's build our AlexNet\n",
        "![](assets/AlexNet.jpeg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes: int = 10, dropout: float = 0.5) -> None:\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIT4IGppv_ql"
      },
      "outputs": [],
      "source": [
        "model = AlexNet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujZRzrUDu2yp"
      },
      "outputs": [],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = model.cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
        "epochs = 100\n",
        "pbar = tqdm(range(epochs))\n",
        "best_accuracy = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "time_init = time() # record the time at which training started\n",
        "\n",
        "for e in pbar:\n",
        "    running_loss = 0\n",
        "    for images, gt_labels in tqdm(trainloader):\n",
        "        images = images.cuda()\n",
        "        gt_labels = gt_labels.cuda()\n",
        "    \n",
        "        # Training pass\n",
        "        optimizer.zero_grad() # reset the gradients of model weights\n",
        "        \n",
        "        output = model(images)\n",
        "        loss = criterion(output, gt_labels)\n",
        "        \n",
        "        # Calculate the gradients of the learnable parameters\n",
        "        loss.backward()\n",
        "        \n",
        "        # Modify the model weights as per the gradients\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    average_loss = running_loss/len(trainloader)\n",
        "    \n",
        "    # perform validation\n",
        "    correct_count = 0\n",
        "    total_count = 0\n",
        "    for images,gt_labels in valloader:\n",
        "      pred_probs = model(images.cuda())\n",
        "      predicted_labels = torch.argmax(pred_probs, dim=-1)\n",
        "\n",
        "      for i in range(len(gt_labels)):\n",
        "        if predicted_labels[i]==gt_labels[i]:\n",
        "          correct_count = correct_count+1\n",
        "        total_count = total_count+1       \n",
        "\n",
        "    accuracy = correct_count/total_count\n",
        "    \n",
        "    # save the model weights\n",
        "    if accuracy>=best_accuracy:\n",
        "      best_accuracy = accuracy\n",
        "      torch.save(model, './best_flower_model.pt')\n",
        "    torch.save(model, './last_flower_model.pt') \n",
        "\n",
        "    print(f\"\\nEpoch {e} - Training loss: {average_loss}, val accuracy : {accuracy}\")\n",
        "print(f\"Training Time (in minutes) = {(time()-time_init)/60}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "images, gt_labels = next(iter(valloader))\n",
        "\n",
        "with torch.no_grad():\n",
        "    pred_probs = model(images.cuda())\n",
        "\n",
        "predicted_labels = torch.argmax(pred_probs, dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Result Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize all images in the minibatch\n",
        "figure = plt.figure()\n",
        "total_samples = 8\n",
        "for index in range(1,total_samples+1):\n",
        "    ax = plt.subplot(2, 4, index)\n",
        "    ax.set_xlabel(classes[gt_labels[index-1].item()])\n",
        "    # plt.axis('off')\n",
        "    plt.imshow(images[index-1].squeeze().permute(1,2,0).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Ground truth labels : {gt_labels}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Predicted labels : {predicted_labels}\",)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize all images in the minibatch\n",
        "figure = plt.figure()\n",
        "total_samples = 8\n",
        "for index in range(1,total_samples+1):\n",
        "    ax = plt.subplot(2, 4, index)\n",
        "    ax.set_xlabel(classes[predicted_labels[index-1].item()])\n",
        "    # plt.axis('off')\n",
        "    plt.imshow(images[index-1].squeeze().permute(1,2,0).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "correct_count = 0\n",
        "total_count = 0\n",
        "for i in range(len(gt_labels)):\n",
        "  img = images[i]\n",
        "  if predicted_labels[i]==gt_labels[i]:\n",
        "    correct_count = correct_count+1\n",
        "  total_count = total_count+1\n",
        "accuracy = correct_count/total_count\n",
        "print(f\"The accuracy on the minibatch is : {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "correct_count = 0\n",
        "total_count = 0\n",
        "\n",
        "for images,gt_labels in valloader:\n",
        "  pred_probs = model(images.cuda())\n",
        "  predicted_labels = torch.argmax(pred_probs, dim=-1)\n",
        "\n",
        "  for i in range(len(gt_labels)):\n",
        "    if predicted_labels[i]==gt_labels[i]:\n",
        "      correct_count = correct_count+1\n",
        "    total_count = total_count+1       \n",
        "\n",
        "accuracy = correct_count/total_count\n",
        "print(f\"Number of validation images = {total_count}\\n\")\n",
        "print(f\"Model Accuracy = {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "wCn3pKjc_iTF",
        "NfSyK7w6_7Ba",
        "VFOu2DDNPAju",
        "GgZgs_bPQMwg"
      ],
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.7.13 ('torchenv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0c9fb112d4624b5e4fa7b873160be5d487c9f44e6948be985e0928a4033755e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
